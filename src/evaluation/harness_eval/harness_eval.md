This evaluation is a modified version of the [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness). The modification allows for the saving of text generated by the model during the evaluation process.

## Run Harness Evaluation

See harness_eval.sh for an example

## Customized Mitigated Benchmarks

For example, to run this evaluation on mitigated gsm8k (adding typo), please go to this directory

"bdc_mitigation_assessment/src/evaluation/harness_eval/lm-evaluation-harness/lm_eval/tasks/gsm8k"

, and create gsm8k-typo.yaml. The .yaml file should indicate the path to your mitigated benchmark (data_files: ../data/contamination/gsm8k/typo.csv)

## Parsing Results

After completing the evaluation, run parse_results.py to parse the generated texts and get evaluation vectors.
